{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GrWIJywLV-V"
   },
   "source": [
    "## Train a Detector on A Customized Dataset\n",
    "\n",
    "To train a new detector, there are usually three things to do:\n",
    "1. Support a new dataset\n",
    "2. Modify the config\n",
    "3. Train a new detector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E73y5Lru-wBx"
   },
   "source": [
    "### Support a new dataset\n",
    "\n",
    "There are three ways to support a new dataset in MMDetection:\n",
    "  1. Reorganize the dataset into a COCO format\n",
    "  2. Reorganize the dataset into a middle format\n",
    "  3. Implement a new dataset\n",
    "\n",
    "We recommend the first two methods, as they are usually easier than the third.\n",
    "\n",
    "In this tutorial, we give an example that converts the data into COCO format because MMDetection **only support evaluating mask AP of dataset in COCO format for now**. Other methods and more advanced usages can be found in the [doc](https://mmdetection.readthedocs.io/en/latest/advanced_guides/customize_dataset.html).\n",
    "\n",
    "First, let's download the [the balloon dataset](https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ro6JhfBVRYYX"
   },
   "source": [
    "# Check the directory structure of the tiny data\n",
    "\n",
    "# Install tree first in your terminal(linux)\n",
    "sudo apt-get -q install tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h85AtunjRvx4"
   },
   "source": [
    "Checking the label corresponding to the instance split ID after the data format conversion is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zaYkWbxORwZq",
    "outputId": "02ad1ff6-f138-49af-b733-1d23c51557f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Category ID: 1, Category Name: grape_berry\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Path to load the COCO annotation file\n",
    "annotation_file = '/mmdetection/grape/data/resize_blur10/train/annotation_coco.json'\n",
    "\n",
    "# Initialise the COCO object\n",
    "coco = COCO(annotation_file)\n",
    "\n",
    "# Get all category tags and corresponding category IDs\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "category_id_to_name = {cat['id']: cat['name'] for cat in categories}\n",
    "\n",
    "# Print all category IDs and corresponding category names\n",
    "for category_id, category_name in category_id_to_name.items():\n",
    "    print(f\"Category ID: {category_id}, Category Name: {category_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwqJOpBe-bMj"
   },
   "source": [
    "### Modify the config\n",
    "\n",
    "In the next step, we need to modify the config for the training.\n",
    "To accelerate the process, we finetune a detector using a pre-trained detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hamZrlnH-YDD"
   },
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "cfg = Config.fromfile('../configs/mask_rcnn/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HntziLGq-92Z"
   },
   "source": [
    "Given a config that trains a Mask R-CNN on COCO dataset, we need to modify some values to use it for training on the balloon dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pUbwD8uV0PR8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mmengine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmmengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_random_seed\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Modify dataset classes and color\u001b[39;00m\n\u001b[1;32m      4\u001b[0m cfg\u001b[38;5;241m.\u001b[39mmetainfo \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrape_berry\u001b[39m\u001b[38;5;124m'\u001b[39m, ),\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpalette\u001b[39m\u001b[38;5;124m'\u001b[39m: [\n\u001b[1;32m      7\u001b[0m         (\u001b[38;5;241m220\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m60\u001b[39m),\n\u001b[1;32m      8\u001b[0m     ]\n\u001b[1;32m      9\u001b[0m }\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mmengine'"
     ]
    }
   ],
   "source": [
    "from mmengine.runner import set_random_seed\n",
    "\n",
    "# Modify dataset classes and color\n",
    "cfg.metainfo = {\n",
    "    'classes': ('grape_berry', ),\n",
    "    'palette': [\n",
    "        (220, 20, 60),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Modify dataset type and path\n",
    "# 使用する学習データのパスを指定\n",
    "cfg.data_root = './data/resize_blur10'\n",
    "\n",
    "cfg.train_dataloader.dataset.ann_file = 'train/annotation_coco.json'\n",
    "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.train_dataloader.dataset.data_prefix.img = 'train/color'\n",
    "cfg.train_dataloader.dataset.metainfo = cfg.metainfo\n",
    "\n",
    "cfg.val_dataloader.dataset.ann_file = 'val/annotation_coco.json'\n",
    "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.val_dataloader.dataset.data_prefix.img = 'val/color/'\n",
    "cfg.val_dataloader.dataset.metainfo = cfg.metainfo\n",
    "\n",
    "cfg.test_dataloader = cfg.val_dataloader\n",
    "\n",
    "# Modify metric config\n",
    "cfg.val_evaluator.ann_file = cfg.data_root+'/'+'val/annotation_coco.json'\n",
    "cfg.test_evaluator = cfg.val_evaluator\n",
    "\n",
    "# Modify num classes of the model in box head and mask head\n",
    "cfg.model.roi_head.bbox_head.num_classes = 1\n",
    "cfg.model.roi_head.mask_head.num_classes = 1\n",
    "\n",
    "# We can still the pre-trained Mask RCNN model to obtain a higher performance\n",
    "cfg.load_from = '../checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "\n",
    "\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "cfg.train_cfg.val_interval = 3\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.default_hooks.checkpoint.interval = 3\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.optim_wrapper.optimizer.lr = 0.02 / 8\n",
    "cfg.default_hooks.logger.interval = 10\n",
    "\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "# cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "\n",
    "# We can also use tensorboard to log the training process\n",
    "cfg.visualizer.vis_backends.append({\"type\":'TensorboardVisBackend'})\n",
    "\n",
    "#------------------------------------------------------\n",
    "config=f'../configs/mask_rcnn/mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco.py'\n",
    "with open(config, 'w') as f:\n",
    "    f.write(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "111W_oZV_3wa"
   },
   "source": [
    "### Train a new detector\n",
    "\n",
    "Finally, lets initialize the dataset and detector, then train a new detector!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JiqDnPdAMGyg",
    "outputId": "0de25679-3541-488e-eceb-5b5400f92745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/15 04:18:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.8 (main, Nov  4 2022, 13:48:29) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1817293139\n",
      "    GPU 0,1,2,3,4,5,6,7: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /opt/conda\n",
      "    NVCC: Cuda compilation tools, release 11.6, V11.6.124\n",
      "    GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "    PyTorch: 1.13.1\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.6\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1817293139\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "05/15 04:18:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "data_root = './data/resize_blur10'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=3, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "load_from = '../checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "metainfo = dict(\n",
      "    classes=('grape_berry', ), palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=50,\n",
      "        frozen_stages=1,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://detectron2/resnet50_caffe',\n",
      "            type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=False, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='caffe',\n",
      "        type='ResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=False,\n",
      "        mean=[\n",
      "            103.53,\n",
      "            116.28,\n",
      "            123.675,\n",
      "        ],\n",
      "        pad_mask=True,\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            1.0,\n",
      "            1.0,\n",
      "            1.0,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=1,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        mask_head=dict(\n",
      "            conv_out_channels=256,\n",
      "            in_channels=256,\n",
      "            loss_mask=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "            num_classes=1,\n",
      "            num_convs=4,\n",
      "            type='FCNMaskHead'),\n",
      "        mask_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            mask_thr_binary=0.5,\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.05),\n",
      "        rpn=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=1000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            mask_size=28,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='MaskRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.0025, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=12,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            8,\n",
      "            11,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='val/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val/color/'),\n",
      "        data_root='./data/resize_blur10',\n",
      "        metainfo=dict(classes=('grape_berry', ), palette=[\n",
      "            (\n",
      "                220,\n",
      "                20,\n",
      "                60,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='./data/resize_blur10/val/annotation_coco.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=12, type='EpochBasedTrainLoop', val_interval=3)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='train/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='train/color'),\n",
      "        data_root='./data/resize_blur10',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(classes=('grape_berry', ), palette=[\n",
      "            (\n",
      "                220,\n",
      "                20,\n",
      "                60,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                poly2mask=False,\n",
      "                type='LoadAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_mask=True),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                scales=[\n",
      "                    (\n",
      "                        1333,\n",
      "                        640,\n",
      "                    ),\n",
      "                    (\n",
      "                        1333,\n",
      "                        672,\n",
      "                    ),\n",
      "                    (\n",
      "                        1333,\n",
      "                        704,\n",
      "                    ),\n",
      "                    (\n",
      "                        1333,\n",
      "                        736,\n",
      "                    ),\n",
      "                    (\n",
      "                        1333,\n",
      "                        768,\n",
      "                    ),\n",
      "                    (\n",
      "                        1333,\n",
      "                        800,\n",
      "                    ),\n",
      "                ],\n",
      "                type='RandomChoiceResize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        poly2mask=False,\n",
      "        type='LoadAnnotations',\n",
      "        with_bbox=True,\n",
      "        with_mask=True),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        scales=[\n",
      "            (\n",
      "                1333,\n",
      "                640,\n",
      "            ),\n",
      "            (\n",
      "                1333,\n",
      "                672,\n",
      "            ),\n",
      "            (\n",
      "                1333,\n",
      "                704,\n",
      "            ),\n",
      "            (\n",
      "                1333,\n",
      "                736,\n",
      "            ),\n",
      "            (\n",
      "                1333,\n",
      "                768,\n",
      "            ),\n",
      "            (\n",
      "                1333,\n",
      "                800,\n",
      "            ),\n",
      "        ],\n",
      "        type='RandomChoiceResize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='val/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val/color/'),\n",
      "        data_root='./data/resize_blur10',\n",
      "        metainfo=dict(classes=('grape_berry', ), palette=[\n",
      "            (\n",
      "                220,\n",
      "                20,\n",
      "                60,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='./data/resize_blur10/val/annotation_coco.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='TensorboardVisBackend'),\n",
      "    ])\n",
      "work_dir = './tutorial_exps'\n",
      "\n",
      "05/15 04:18:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "05/15 04:18:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "05/15 04:18:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://detectron2/resnet50_caffe\n",
      "05/15 04:18:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://detectron2/resnet50_caffe\n",
      "05/15 04:18:43 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: conv1.bias\n",
      "\n",
      "Loads checkpoint by local backend from path: ../checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([4]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "05/15 04:18:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from ../checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth\n",
      "05/15 04:18:43 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "05/15 04:18:43 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "05/15 04:18:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /mmdetection/grape/tutorial_exps.\n",
      "05/15 04:18:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][10/40]  lr: 4.7545e-05  eta: 0:02:59  time: 0.3817  data_time: 0.0108  memory: 2820  loss: 6.0195  loss_rpn_cls: 2.2036  loss_rpn_bbox: 0.2381  loss_cls: 0.6788  acc: 71.1914  loss_bbox: 0.6771  loss_mask: 2.2218\n",
      "05/15 04:18:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][20/40]  lr: 9.7595e-05  eta: 0:02:06  time: 0.2745  data_time: 0.0074  memory: 2819  loss: 4.4806  loss_rpn_cls: 1.3687  loss_rpn_bbox: 0.2231  loss_cls: 0.6337  acc: 75.0000  loss_bbox: 0.6540  loss_mask: 1.6010\n",
      "05/15 04:18:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][30/40]  lr: 1.4765e-04  eta: 0:01:47  time: 0.2388  data_time: 0.0064  memory: 2819  loss: 3.7765  loss_rpn_cls: 1.0781  loss_rpn_bbox: 0.2176  loss_cls: 0.5971  acc: 75.0000  loss_bbox: 0.6450  loss_mask: 1.2386\n",
      "05/15 04:18:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco_20240515_041838\n",
      "05/15 04:18:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][40/40]  lr: 1.9770e-04  eta: 0:01:36  time: 0.2201  data_time: 0.0057  memory: 2819  loss: 3.3722  loss_rpn_cls: 0.9056  loss_rpn_bbox: 0.2146  loss_cls: 0.5732  acc: 75.0000  loss_bbox: 0.6416  loss_mask: 1.0373\n",
      "05/15 04:18:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][10/40]  lr: 2.4775e-04  eta: 0:01:30  time: 0.2110  data_time: 0.0058  memory: 2819  loss: 3.1155  loss_rpn_cls: 0.7891  loss_rpn_bbox: 0.2106  loss_cls: 0.5563  acc: 75.0000  loss_bbox: 0.6476  loss_mask: 0.9119\n",
      "05/15 04:18:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][20/40]  lr: 2.9780e-04  eta: 0:01:25  time: 0.1684  data_time: 0.0046  memory: 2819  loss: 2.3145  loss_rpn_cls: 0.4091  loss_rpn_bbox: 0.1986  loss_cls: 0.5142  acc: 75.0000  loss_bbox: 0.6452  loss_mask: 0.5474\n",
      "05/15 04:18:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][30/40]  lr: 3.4785e-04  eta: 0:01:21  time: 0.1674  data_time: 0.0048  memory: 2819  loss: 2.1278  loss_rpn_cls: 0.3556  loss_rpn_bbox: 0.1933  loss_cls: 0.4876  acc: 77.8320  loss_bbox: 0.6580  loss_mask: 0.4333\n",
      "05/15 04:18:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco_20240515_041838\n",
      "05/15 04:18:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][40/40]  lr: 3.9790e-04  eta: 0:01:17  time: 0.1661  data_time: 0.0047  memory: 2819  loss: 2.0383  loss_rpn_cls: 0.3026  loss_rpn_bbox: 0.1870  loss_cls: 0.4698  acc: 83.1055  loss_bbox: 0.6706  loss_mask: 0.4084\n",
      "05/15 04:19:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][10/40]  lr: 4.4795e-04  eta: 0:01:14  time: 0.1660  data_time: 0.0053  memory: 2819  loss: 1.9910  loss_rpn_cls: 0.2657  loss_rpn_bbox: 0.1817  loss_cls: 0.4547  acc: 83.8867  loss_bbox: 0.6870  loss_mask: 0.4018\n",
      "05/15 04:19:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][20/40]  lr: 4.9800e-04  eta: 0:01:11  time: 0.1639  data_time: 0.0048  memory: 2819  loss: 1.9385  loss_rpn_cls: 0.2387  loss_rpn_bbox: 0.1800  loss_cls: 0.4357  acc: 86.8164  loss_bbox: 0.6885  loss_mask: 0.3957\n",
      "05/15 04:19:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][30/40]  lr: 5.4805e-04  eta: 0:01:08  time: 0.1626  data_time: 0.0047  memory: 2819  loss: 1.8867  loss_rpn_cls: 0.2158  loss_rpn_bbox: 0.1797  loss_cls: 0.4171  acc: 83.8867  loss_bbox: 0.6826  loss_mask: 0.3915\n",
      "05/15 04:19:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco_20240515_041838\n",
      "05/15 04:19:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][40/40]  lr: 5.9810e-04  eta: 0:01:05  time: 0.1626  data_time: 0.0045  memory: 2819  loss: 1.8208  loss_rpn_cls: 0.2000  loss_rpn_bbox: 0.1806  loss_cls: 0.3981  acc: 85.5469  loss_bbox: 0.6589  loss_mask: 0.3832\n",
      "05/15 04:19:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "05/15 04:19:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][10/27]    eta: 0:00:01  time: 0.0921  data_time: 0.0336  memory: 882  \n",
      "05/15 04:19:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][20/27]    eta: 0:00:00  time: 0.0772  data_time: 0.0208  memory: 882  \n",
      "05/15 04:19:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.08s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.600\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.393\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.618\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.682\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      "05/15 04:19:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.349 0.600 0.393 0.277 0.618 -1.000\n",
      "05/15 04:19:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=2.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.578\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.388\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.664\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.716\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      "05/15 04:19:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - segm_mAP_copypaste: 0.343 0.578 0.388 0.233 0.664 -1.000\n",
      "05/15 04:19:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][27/27]    coco/bbox_mAP: 0.3490  coco/bbox_mAP_50: 0.6000  coco/bbox_mAP_75: 0.3930  coco/bbox_mAP_s: 0.2770  coco/bbox_mAP_m: 0.6180  coco/bbox_mAP_l: -1.0000  coco/segm_mAP: 0.3430  coco/segm_mAP_50: 0.5780  coco/segm_mAP_75: 0.3880  coco/segm_mAP_s: 0.2330  coco/segm_mAP_m: 0.6640  coco/segm_mAP_l: -1.0000  data_time: 0.0172  time: 0.0731\n",
      "05/15 04:19:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][10/40]  lr: 6.4815e-04  eta: 0:01:03  time: 0.1643  data_time: 0.0052  memory: 2819  loss: 1.7673  loss_rpn_cls: 0.1888  loss_rpn_bbox: 0.1811  loss_cls: 0.3830  acc: 86.0352  loss_bbox: 0.6332  loss_mask: 0.3812\n",
      "05/15 04:19:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][20/40]  lr: 6.9820e-04  eta: 0:01:01  time: 0.1640  data_time: 0.0048  memory: 2819  loss: 1.7099  loss_rpn_cls: 0.1802  loss_rpn_bbox: 0.1798  loss_cls: 0.3712  acc: 88.0859  loss_bbox: 0.6029  loss_mask: 0.3757\n",
      "05/15 04:19:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][30/40]  lr: 7.4825e-04  eta: 0:00:59  time: 0.1640  data_time: 0.0049  memory: 2819  loss: 1.6523  loss_rpn_cls: 0.1722  loss_rpn_bbox: 0.1772  loss_cls: 0.3590  acc: 87.5977  loss_bbox: 0.5729  loss_mask: 0.3710\n",
      "05/15 04:19:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco_20240515_041838\n",
      "05/15 04:19:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][40/40]  lr: 7.9830e-04  eta: 0:00:57  time: 0.1655  data_time: 0.0049  memory: 2819  loss: 1.5994  loss_rpn_cls: 0.1608  loss_rpn_bbox: 0.1740  loss_cls: 0.3516  acc: 88.6719  loss_bbox: 0.5462  loss_mask: 0.3668\n",
      "05/15 04:19:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][10/40]  lr: 8.4835e-04  eta: 0:00:55  time: 0.1680  data_time: 0.0057  memory: 2819  loss: 1.5675  loss_rpn_cls: 0.1502  loss_rpn_bbox: 0.1689  loss_cls: 0.3452  acc: 89.6484  loss_bbox: 0.5371  loss_mask: 0.3661\n",
      "05/15 04:19:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][20/40]  lr: 8.9840e-04  eta: 0:00:53  time: 0.1670  data_time: 0.0050  memory: 2819  loss: 1.5326  loss_rpn_cls: 0.1374  loss_rpn_bbox: 0.1665  loss_cls: 0.3389  acc: 86.3281  loss_bbox: 0.5297  loss_mask: 0.3601\n",
      "05/15 04:19:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][30/40]  lr: 9.4845e-04  eta: 0:00:51  time: 0.1674  data_time: 0.0049  memory: 2819  loss: 1.5044  loss_rpn_cls: 0.1342  loss_rpn_bbox: 0.1655  loss_cls: 0.3299  acc: 88.1836  loss_bbox: 0.5183  loss_mask: 0.3565\n",
      "05/15 04:19:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco_20240515_041838\n",
      "05/15 04:19:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][40/40]  lr: 9.9850e-04  eta: 0:00:49  time: 0.1673  data_time: 0.0047  memory: 2819  loss: 1.5122  loss_rpn_cls: 0.1522  loss_rpn_bbox: 0.1626  loss_cls: 0.3338  acc: 84.8633  loss_bbox: 0.5088  loss_mask: 0.3549\n",
      "05/15 04:19:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][10/40]  lr: 1.0485e-03  eta: 0:00:47  time: 0.1659  data_time: 0.0050  memory: 2819  loss: 1.5262  loss_rpn_cls: 0.1620  loss_rpn_bbox: 0.1635  loss_cls: 0.3338  acc: 85.1562  loss_bbox: 0.5108  loss_mask: 0.3562\n",
      "05/15 04:19:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][20/40]  lr: 1.0986e-03  eta: 0:00:45  time: 0.1634  data_time: 0.0045  memory: 2819  loss: 1.5048  loss_rpn_cls: 0.1617  loss_rpn_bbox: 0.1626  loss_cls: 0.3322  acc: 88.4766  loss_bbox: 0.4983  loss_mask: 0.3500\n",
      "05/15 04:19:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][30/40]  lr: 1.1486e-03  eta: 0:00:43  time: 0.1634  data_time: 0.0045  memory: 2819  loss: 1.4946  loss_rpn_cls: 0.1639  loss_rpn_bbox: 0.1606  loss_cls: 0.3313  acc: 87.6953  loss_bbox: 0.4890  loss_mask: 0.3498\n",
      "05/15 04:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco_20240515_041838\n",
      "05/15 04:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][40/40]  lr: 1.1987e-03  eta: 0:00:41  time: 0.1622  data_time: 0.0045  memory: 2819  loss: 1.4850  loss_rpn_cls: 0.1632  loss_rpn_bbox: 0.1608  loss_cls: 0.3315  acc: 87.0117  loss_bbox: 0.4823  loss_mask: 0.3471\n",
      "05/15 04:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
      "05/15 04:19:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][10/27]    eta: 0:00:01  time: 0.0721  data_time: 0.0168  memory: 882  \n",
      "05/15 04:19:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][20/27]    eta: 0:00:00  time: 0.0700  data_time: 0.0150  memory: 882  \n",
      "05/15 04:19:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.389\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.675\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.431\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.297\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.644\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.432\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.432\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.432\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.699\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      "05/15 04:19:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.389 0.675 0.431 0.297 0.644 -1.000\n",
      "05/15 04:19:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=2.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.634\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.419\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.668\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.707\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      "05/15 04:19:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - segm_mAP_copypaste: 0.364 0.634 0.419 0.246 0.668 -1.000\n",
      "05/15 04:19:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][27/27]    coco/bbox_mAP: 0.3890  coco/bbox_mAP_50: 0.6750  coco/bbox_mAP_75: 0.4310  coco/bbox_mAP_s: 0.2970  coco/bbox_mAP_m: 0.6440  coco/bbox_mAP_l: -1.0000  coco/segm_mAP: 0.3640  coco/segm_mAP_50: 0.6340  coco/segm_mAP_75: 0.4190  coco/segm_mAP_s: 0.2460  coco/segm_mAP_m: 0.6680  coco/segm_mAP_l: -1.0000  data_time: 0.0110  time: 0.0685\n",
      "05/15 04:19:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][10/40]  lr: 1.2487e-03  eta: 0:00:39  time: 0.1626  data_time: 0.0053  memory: 2819  loss: 1.4505  loss_rpn_cls: 0.1401  loss_rpn_bbox: 0.1628  loss_cls: 0.3235  acc: 87.8906  loss_bbox: 0.4796  loss_mask: 0.3446\n",
      "05/15 04:19:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][20/40]  lr: 1.2988e-03  eta: 0:00:38  time: 0.1633  data_time: 0.0050  memory: 2819  loss: 1.4099  loss_rpn_cls: 0.1254  loss_rpn_bbox: 0.1603  loss_cls: 0.3152  acc: 89.9414  loss_bbox: 0.4703  loss_mask: 0.3386\n",
      "05/15 04:19:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][30/40]  lr: 1.3488e-03  eta: 0:00:36  time: 0.1643  data_time: 0.0051  memory: 2819  loss: 1.3995  loss_rpn_cls: 0.1218  loss_rpn_bbox: 0.1603  loss_cls: 0.3105  acc: 89.0625  loss_bbox: 0.4703  loss_mask: 0.3366\n",
      "05/15 04:19:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco_20240515_041838\n",
      "05/15 04:19:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][40/40]  lr: 1.3989e-03  eta: 0:00:34  time: 0.1637  data_time: 0.0050  memory: 2819  loss: 1.3813  loss_rpn_cls: 0.1224  loss_rpn_bbox: 0.1592  loss_cls: 0.3044  acc: 90.4297  loss_bbox: 0.4655  loss_mask: 0.3297\n",
      "05/15 04:19:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][10/40]  lr: 1.4489e-03  eta: 0:00:32  time: 0.1663  data_time: 0.0060  memory: 2819  loss: 1.3665  loss_rpn_cls: 0.1166  loss_rpn_bbox: 0.1566  loss_cls: 0.3014  acc: 87.4023  loss_bbox: 0.4655  loss_mask: 0.3264\n",
      "05/15 04:19:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][20/40]  lr: 1.4990e-03  eta: 0:00:31  time: 0.1674  data_time: 0.0057  memory: 2819  loss: 1.3391  loss_rpn_cls: 0.1114  loss_rpn_bbox: 0.1520  loss_cls: 0.2958  acc: 89.4531  loss_bbox: 0.4605  loss_mask: 0.3194\n",
      "05/15 04:19:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][30/40]  lr: 1.5490e-03  eta: 0:00:29  time: 0.1669  data_time: 0.0057  memory: 2819  loss: 1.3292  loss_rpn_cls: 0.1108  loss_rpn_bbox: 0.1504  loss_cls: 0.2988  acc: 89.4531  loss_bbox: 0.4556  loss_mask: 0.3135\n",
      "05/15 04:19:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco_20240515_041838\n",
      "05/15 04:19:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][40/40]  lr: 1.5991e-03  eta: 0:00:27  time: 0.1664  data_time: 0.0056  memory: 2819  loss: 1.3387  loss_rpn_cls: 0.1205  loss_rpn_bbox: 0.1497  loss_cls: 0.3043  acc: 88.3789  loss_bbox: 0.4516  loss_mask: 0.3126\n",
      "05/15 04:19:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][10/40]  lr: 1.6491e-04  eta: 0:00:25  time: 0.1686  data_time: 0.0065  memory: 2819  loss: 1.3469  loss_rpn_cls: 0.1188  loss_rpn_bbox: 0.1488  loss_cls: 0.3074  acc: 85.9375  loss_bbox: 0.4570  loss_mask: 0.3148\n",
      "05/15 04:19:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][20/40]  lr: 1.6992e-04  eta: 0:00:24  time: 0.1670  data_time: 0.0056  memory: 2819  loss: 1.3307  loss_rpn_cls: 0.1192  loss_rpn_bbox: 0.1464  loss_cls: 0.3056  acc: 87.9883  loss_bbox: 0.4484  loss_mask: 0.3111\n",
      "05/15 04:19:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][30/40]  lr: 1.7492e-04  eta: 0:00:22  time: 0.1650  data_time: 0.0052  memory: 2819  loss: 1.3365  loss_rpn_cls: 0.1211  loss_rpn_bbox: 0.1464  loss_cls: 0.3064  acc: 88.8672  loss_bbox: 0.4496  loss_mask: 0.3130\n",
      "05/15 04:20:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco_20240515_041838\n",
      "05/15 04:20:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][40/40]  lr: 1.7993e-04  eta: 0:00:20  time: 0.1639  data_time: 0.0051  memory: 2819  loss: 1.3177  loss_rpn_cls: 0.1190  loss_rpn_bbox: 0.1442  loss_cls: 0.3006  acc: 90.0391  loss_bbox: 0.4438  loss_mask: 0.3100\n",
      "05/15 04:20:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
      "05/15 04:20:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][10/27]    eta: 0:00:01  time: 0.0677  data_time: 0.0118  memory: 882  \n",
      "05/15 04:20:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][20/27]    eta: 0:00:00  time: 0.0678  data_time: 0.0122  memory: 882  \n",
      "05/15 04:20:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.91s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.715\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.538\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.367\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.732\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.503\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.503\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.503\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.780\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      "05/15 04:20:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.462 0.715 0.538 0.367 0.732 -1.000\n",
      "05/15 04:20:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=2.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.677\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.510\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.752\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.467\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.467\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.786\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      "05/15 04:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - segm_mAP_copypaste: 0.434 0.677 0.510 0.309 0.752 -1.000\n",
      "05/15 04:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [9][27/27]    coco/bbox_mAP: 0.4620  coco/bbox_mAP_50: 0.7150  coco/bbox_mAP_75: 0.5380  coco/bbox_mAP_s: 0.3670  coco/bbox_mAP_m: 0.7320  coco/bbox_mAP_l: -1.0000  coco/segm_mAP: 0.4340  coco/segm_mAP_50: 0.6770  coco/segm_mAP_75: 0.5100  coco/segm_mAP_s: 0.3090  coco/segm_mAP_m: 0.7520  coco/segm_mAP_l: -1.0000  data_time: 0.0130  time: 0.0659\n",
      "05/15 04:20:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][10/40]  lr: 1.8493e-04  eta: 0:00:18  time: 0.1643  data_time: 0.0053  memory: 2819  loss: 1.2826  loss_rpn_cls: 0.1067  loss_rpn_bbox: 0.1405  loss_cls: 0.2926  acc: 90.6250  loss_bbox: 0.4387  loss_mask: 0.3041\n",
      "05/15 04:20:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][20/40]  lr: 1.8994e-04  eta: 0:00:17  time: 0.1625  data_time: 0.0046  memory: 2819  loss: 1.2592  loss_rpn_cls: 0.1040  loss_rpn_bbox: 0.1392  loss_cls: 0.2892  acc: 91.4062  loss_bbox: 0.4263  loss_mask: 0.3006\n",
      "05/15 04:20:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][30/40]  lr: 1.9494e-04  eta: 0:00:15  time: 0.1629  data_time: 0.0046  memory: 2819  loss: 1.2496  loss_rpn_cls: 0.1008  loss_rpn_bbox: 0.1379  loss_cls: 0.2867  acc: 89.3555  loss_bbox: 0.4252  loss_mask: 0.2990\n",
      "05/15 04:20:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco_20240515_041838\n",
      "05/15 04:20:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][40/40]  lr: 1.9995e-04  eta: 0:00:13  time: 0.1633  data_time: 0.0046  memory: 2819  loss: 1.2402  loss_rpn_cls: 0.0972  loss_rpn_bbox: 0.1366  loss_cls: 0.2858  acc: 89.6484  loss_bbox: 0.4226  loss_mask: 0.2981\n",
      "05/15 04:20:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][10/40]  lr: 2.0495e-04  eta: 0:00:11  time: 0.1650  data_time: 0.0053  memory: 2819  loss: 1.2439  loss_rpn_cls: 0.0975  loss_rpn_bbox: 0.1378  loss_cls: 0.2839  acc: 89.6484  loss_bbox: 0.4252  loss_mask: 0.2996\n",
      "05/15 04:20:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][20/40]  lr: 2.0996e-04  eta: 0:00:10  time: 0.1645  data_time: 0.0052  memory: 2819  loss: 1.2414  loss_rpn_cls: 0.0960  loss_rpn_bbox: 0.1379  loss_cls: 0.2830  acc: 91.3086  loss_bbox: 0.4257  loss_mask: 0.2987\n",
      "05/15 04:20:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][30/40]  lr: 2.1496e-04  eta: 0:00:08  time: 0.1637  data_time: 0.0050  memory: 2819  loss: 1.2345  loss_rpn_cls: 0.0952  loss_rpn_bbox: 0.1381  loss_cls: 0.2806  acc: 88.8672  loss_bbox: 0.4236  loss_mask: 0.2971\n",
      "05/15 04:20:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco_20240515_041838\n",
      "05/15 04:20:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][40/40]  lr: 2.1997e-04  eta: 0:00:06  time: 0.1634  data_time: 0.0049  memory: 2819  loss: 1.2324  loss_rpn_cls: 0.0956  loss_rpn_bbox: 0.1386  loss_cls: 0.2803  acc: 90.4297  loss_bbox: 0.4206  loss_mask: 0.2973\n",
      "05/15 04:20:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][10/40]  lr: 2.2497e-05  eta: 0:00:05  time: 0.1635  data_time: 0.0051  memory: 2819  loss: 1.2393  loss_rpn_cls: 0.1015  loss_rpn_bbox: 0.1390  loss_cls: 0.2801  acc: 90.4297  loss_bbox: 0.4203  loss_mask: 0.2984\n",
      "05/15 04:20:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][20/40]  lr: 2.2998e-05  eta: 0:00:03  time: 0.1620  data_time: 0.0045  memory: 2819  loss: 1.2351  loss_rpn_cls: 0.1007  loss_rpn_bbox: 0.1369  loss_cls: 0.2823  acc: 88.8672  loss_bbox: 0.4176  loss_mask: 0.2975\n",
      "05/15 04:20:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][30/40]  lr: 2.3498e-05  eta: 0:00:01  time: 0.1621  data_time: 0.0043  memory: 2819  loss: 1.2335  loss_rpn_cls: 0.0988  loss_rpn_bbox: 0.1374  loss_cls: 0.2813  acc: 89.2578  loss_bbox: 0.4165  loss_mask: 0.2995\n",
      "05/15 04:20:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco_20240515_041838\n",
      "05/15 04:20:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][40/40]  lr: 2.3999e-05  eta: 0:00:00  time: 0.1632  data_time: 0.0042  memory: 2819  loss: 1.2403  loss_rpn_cls: 0.0983  loss_rpn_bbox: 0.1373  loss_cls: 0.2838  acc: 87.9883  loss_bbox: 0.4205  loss_mask: 0.3003\n",
      "05/15 04:20:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12 epochs\n",
      "05/15 04:20:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][10/27]    eta: 0:00:01  time: 0.0714  data_time: 0.0157  memory: 882  \n",
      "05/15 04:20:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][20/27]    eta: 0:00:00  time: 0.0692  data_time: 0.0157  memory: 882  \n",
      "05/15 04:20:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.89s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.727\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.553\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.729\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.509\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.509\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.415\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.774\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      "05/15 04:20:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.468 0.727 0.553 0.377 0.729 -1.000\n",
      "05/15 04:20:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=1.93s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.682\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.509\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.746\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.464\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.464\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.781\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      "05/15 04:20:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - segm_mAP_copypaste: 0.434 0.682 0.509 0.311 0.746 -1.000\n",
      "05/15 04:20:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][27/27]    coco/bbox_mAP: 0.4680  coco/bbox_mAP_50: 0.7270  coco/bbox_mAP_75: 0.5530  coco/bbox_mAP_s: 0.3770  coco/bbox_mAP_m: 0.7290  coco/bbox_mAP_l: -1.0000  coco/segm_mAP: 0.4340  coco/segm_mAP_50: 0.6820  coco/segm_mAP_75: 0.5090  coco/segm_mAP_s: 0.3110  coco/segm_mAP_m: 0.7460  coco/segm_mAP_l: -1.0000  data_time: 0.0169  time: 0.0706\n"
     ]
    }
   ],
   "source": [
    "!python ../tools/train.py {config}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vYQF5K2NqqI"
   },
   "source": [
    "### Understand the log\n",
    "From the log, we can have a basic understanding on the training process and know how well the detector is trained.\n",
    "\n",
    "First, since the dataset we are using is small, we loaded a Mask R-CNN model and finetune it for detection. Because the original Mask R-CNN is trained on COCO dataset that contains 80 classes but KITTI Tiny dataset only have 3 classes. Therefore, the last FC layers of the pre-trained Mask R-CNN for classification and regression have different weight shape and are not used. The pre-trained weights of mask prediction layer `mask_head.conv_logits` also does not matches the current model and is not used due to similar reason.\n",
    "\n",
    "Third, after training, the detector is evaluated by the default COCO-style evaluation. The results show that the detector achieves 79.6 bbox AP and 81.5 mask AP on the val dataset, not bad!\n",
    "\n",
    " We can also check the tensorboard to see the curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gbLNlJR-RYYd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.ustc.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.15.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (60.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.28.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.60.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.26.3)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.19.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.27.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorboard  -i https://mirrors.ustc.edu.cn/pypi/web/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PW2NAam_7irv"
   },
   "outputs": [],
   "source": [
    "# load tensorboard in jupyter notebook\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4G9MCbL2RYYd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 73392), started 13 days, 1:31:43 ago. (Use '!kill 73392' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-629f6fbed82c07cd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-629f6fbed82c07cd\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see curves in tensorboard\n",
    "# if you see <IPython.core.display.HTML object> please run it again\n",
    "%tensorboard --logdir tutorial_exps/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfQ-yspZLuuI"
   },
   "source": [
    "## Test the Trained Detector\n",
    "\n",
    "After finetuning the detector, let's visualize the prediction results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1つの写真に対しての検出結果を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: tutorial_exps/epoch_12.pth\n",
      "<DetDataSample(\n",
      "\n",
      "    META INFORMATION\n",
      "    img_path: None\n",
      "    pad_shape: (800, 800)\n",
      "    scale_factor: (1.6666666666666667, 1.6666666666666667)\n",
      "    batch_input_shape: (800, 800)\n",
      "    img_shape: (800, 800)\n",
      "    ori_shape: (480, 480)\n",
      "    img_id: 0\n",
      "\n",
      "    DATA FIELDS\n",
      "    pred_instances: <InstanceData(\n",
      "        \n",
      "            META INFORMATION\n",
      "        \n",
      "            DATA FIELDS\n",
      "            scores: tensor([0.9290, 0.9186, 0.7397, 0.6362, 0.6198, 0.5769, 0.5689, 0.5118, 0.4123,\n",
      "                        0.1903, 0.1708, 0.1609, 0.1485, 0.1140, 0.0922, 0.0910, 0.0886, 0.0818,\n",
      "                        0.0790, 0.0695, 0.0684, 0.0673, 0.0630, 0.0628, 0.0624, 0.0623, 0.0602,\n",
      "                        0.0599, 0.0588, 0.0567, 0.0565, 0.0533, 0.0525, 0.0521, 0.0508])\n",
      "            bboxes: tensor([[210.2939, 267.8679, 234.7567, 290.8976],\n",
      "                        [249.0886, 323.2330, 269.6214, 348.3803],\n",
      "                        [183.0977, 408.9762, 359.3264, 458.2531],\n",
      "                        [182.4275, 412.9839, 233.8614, 451.7506],\n",
      "                        [142.4615, 430.4807, 181.2262, 448.1616],\n",
      "                        [245.4072, 291.7519, 262.3233, 310.2284],\n",
      "                        [143.0026, 430.4567, 203.0742, 456.7111],\n",
      "                        [229.2255, 304.5001, 246.0553, 328.8028],\n",
      "                        [182.6776, 412.1838, 231.2388, 432.6036],\n",
      "                        [198.0327, 290.6321, 218.1898, 308.8893],\n",
      "                        [176.5021, 327.9667, 374.2816, 457.6564],\n",
      "                        [ 46.6602, 183.4912, 427.0741, 466.8762],\n",
      "                        [200.2435, 225.7978, 209.9317, 243.2668],\n",
      "                        [110.9505,  21.0616, 356.1255, 455.3173],\n",
      "                        [127.8256, 283.5874, 470.1639, 463.6278],\n",
      "                        [360.0610, 129.8075, 389.2740, 162.6225],\n",
      "                        [ 32.8718,  11.7879, 264.9856, 462.7326],\n",
      "                        [183.3944, 265.1490, 201.3469, 282.5356],\n",
      "                        [190.2682, 219.9357, 203.5578, 240.3316],\n",
      "                        [251.3672, 192.4856, 280.1745, 208.4211],\n",
      "                        [228.5290, 410.9111, 247.4095, 421.3117],\n",
      "                        [281.4152, 289.7371, 304.7798, 306.8621],\n",
      "                        [164.7747, 387.4413, 406.8009, 462.8111],\n",
      "                        [208.5410, 251.8296, 235.9098, 281.4033],\n",
      "                        [191.5910, 225.5980, 350.5761, 459.7759],\n",
      "                        [208.3038,  12.6943, 447.0233, 443.0130],\n",
      "                        [224.2917, 406.0267, 308.6178, 427.0092],\n",
      "                        [167.3766, 429.5685, 213.4955, 456.0296],\n",
      "                        [207.2478, 303.6874, 229.9601, 320.7549],\n",
      "                        [319.4124, 271.2542, 332.9066, 290.1029],\n",
      "                        [185.0356, 355.5349, 318.2980, 424.6385],\n",
      "                        [138.6041, 395.7953, 207.1585, 456.8691],\n",
      "                        [276.8246,  13.7864, 308.2905,  58.9309],\n",
      "                        [ 74.1782,  73.2326, 114.3302,  99.6510],\n",
      "                        [ 56.1750,   5.2262, 447.4327, 315.5127]])\n",
      "            labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "            masks: tensor([[[False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         ...,\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False]],\n",
      "                \n",
      "                        [[False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         ...,\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False]],\n",
      "                \n",
      "                        [[False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         ...,\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False]],\n",
      "                \n",
      "                        ...,\n",
      "                \n",
      "                        [[False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         ...,\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False]],\n",
      "                \n",
      "                        [[False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         ...,\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False]],\n",
      "                \n",
      "                        [[False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         ...,\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False],\n",
      "                         [False, False, False,  ..., False, False, False]]])\n",
      "        ) at 0x7fd63829ff70>\n",
      "    ignored_instances: <InstanceData(\n",
      "        \n",
      "            META INFORMATION\n",
      "        \n",
      "            DATA FIELDS\n",
      "            labels: tensor([], dtype=torch.int64)\n",
      "            bboxes: tensor([], size=(0, 4))\n",
      "            masks: BitmapMasks(num_masks=0, height=480, width=480)\n",
      "        ) at 0x7fd63829eef0>\n",
      "    gt_instances: <InstanceData(\n",
      "        \n",
      "            META INFORMATION\n",
      "        \n",
      "            DATA FIELDS\n",
      "            labels: tensor([], dtype=torch.int64)\n",
      "            bboxes: tensor([], size=(0, 4))\n",
      "            masks: BitmapMasks(num_masks=0, height=480, width=480)\n",
      "        ) at 0x7fd63829efb0>\n",
      ") at 0x7fd63829f010>\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "img = mmcv.imread('/mmdetection/grape/data/defisheye/frame0.jpg',channel_order='rgb')\n",
    "checkpoint_file = 'tutorial_exps/epoch_12.pth'\n",
    "model = init_detector(cfg, checkpoint_file, device='cpu')\n",
    "new_result = inference_detector(model, img)\n",
    "print(new_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Before calling Visualizer.get_current_instance(), you should call get_instance(name=xxx) at least once.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmmengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Visualizer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# get built visualizer\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m visualizer_now \u001b[38;5;241m=\u001b[39m \u001b[43mVisualizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_current_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# the dataset_meta is loaded from the checkpoint and\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# then pass to the model in init_detector\u001b[39;00m\n\u001b[1;32m      6\u001b[0m visualizer_now\u001b[38;5;241m.\u001b[39mdataset_meta \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdataset_meta\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/utils/manager.py:143\u001b[0m, in \u001b[0;36mManagerMixin.get_current_instance\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    141\u001b[0m _accquire_lock()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instance_dict:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBefore calling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.get_current_instance(), you \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould call get_instance(name=xxx) at least once.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    146\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instance_dict)))\n\u001b[1;32m    147\u001b[0m _release_lock()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Before calling Visualizer.get_current_instance(), you should call get_instance(name=xxx) at least once."
     ]
    }
   ],
   "source": [
    "from mmengine.visualization import Visualizer\n",
    "# get built visualizer\n",
    "visualizer_now = Visualizer.get_current_instance()\n",
    "# the dataset_meta is loaded from the checkpoint and\n",
    "# then pass to the model in init_detector\n",
    "visualizer_now.dataset_meta = model.dataset_meta\n",
    "# show the results\n",
    "visualizer_now.add_datasample(\n",
    "    'new_result',\n",
    "    img,\n",
    "    data_sample=new_result,\n",
    "    draw_gt=False,\n",
    "    wait_time=0,\n",
    "    out_file=None,\n",
    "    pred_score_thr=0.5\n",
    ")\n",
    "visualizer_now.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フォルダ内の全ての写真に対しての検出結果を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_MuZurfGLq0p",
    "outputId": "4b25759c-8e22-405e-a061-3abc44e38043"
   },
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmengine.visualization import Visualizer\n",
    "from mmdet.registry import VISUALIZERS\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "import os\n",
    "\n",
    "def show_result_pyplot(img_folder_path, output_folder_path):\n",
    "    checkpoint_file = 'tutorial_exps/epoch_12.pth'\n",
    "    model = init_detector(cfg, checkpoint_file, device='cpu')\n",
    "    visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
    "    visualizer.dataset_meta = model.dataset_meta\n",
    "    for img_path in os.listdir(img_folder_path):\n",
    "        img = mmcv.imread(img_folder_path + img_path, channel_order='rgb')\n",
    "        new_result = inference_detector(model, img)\n",
    "        visualizer.add_datasample(\n",
    "            'new_result',\n",
    "            img,\n",
    "            data_sample=new_result,\n",
    "            draw_gt=False,\n",
    "            wait_time=0,\n",
    "            out_file=f'{output_folder_path}/{img_path}',\n",
    "            pred_score_thr=0.5\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "7SSTauCURYYe",
    "outputId": "3becb5ea-cb4e-44f6-d93d-c10194a2263b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: tutorial_exps/epoch_12.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n",
      "/opt/conda/lib/python3.10/site-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.TensorboardVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    }
   ],
   "source": [
    "image_folder = '/mmdetection/grape/data/fisheye/'\n",
    "output_folder = '/mmdetection/grape/data/fisheye_output/'\n",
    "show_result_pyplot(image_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8868640c17582ff5a3e06365ba2fb344ce697cf42d4745ae8b85a9738303c037"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
